%
% This is a borrowed LaTeX template file for lecture notes for CS267,
% Applications of Parallel Computing, UCBerkeley EECS Department.
% Now being used for CMU's 10725 Fall 2012 Optimization course
% taught by Geoff Gordon and Ryan Tibshirani.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi. "pdflatex template.tex" should also work.
%

\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,graphicx}
\usepackage{listing}
\usepackage{mathrsfs}

\usepackage{color}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf 01: Machine Learning
	\hfill July 18th, 2016} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scribes: #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}

   {\bf Note}: {\it Notes for machine learning course of Mitchell.}

   {\bf Disclaimer}: {\it These notes have not been subjected to the
   usual scrutiny reserved for formal publications.  They may be distributed
   outside this class only with the permission of Mr. Yan.}
   \vspace*{4mm}
}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{1}{Decision Tree Learning \& Review of Probability}{Christopher M. Bishop}{Yan Yan}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------
This chapter is based on Lecture 1 and Lecture 2 of Mitchell class, the reading references are  \textit{Pattern Recognition and Machine Learning} of Bishop and \textit{Machine Learning} of Mitchell. Also the PPT file of Andrew Moore and \textit{The Discipline of Machine Learning} were also mentioned.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{The Discipline of Machine Learning} 
\subsection{Defining Questions}
THE filed of machine learning seeks to answer the question:
"How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes?"

Define: A machine learns with respects to a particular task T, performance metric P, and a type of experience E, if the system reliably improves its performance P at task T, following experience E.

Depending on how we specify T, P and E, the learning task might also be called by names such as data mining, autonomous discovery, etc.

Computer Science: how can we build machines that solve problems, and which problems are inherently tractable/intractable?

V.S.

Statistics: what can we inferred from data plus a set of modelling assumptions, with what reliability?

Computer Science has focused primarily on how to manually program computers, ML focused on how to get computer to program themselves from experience, whereas Statistics focus on the what conclusions can be inferred from data.

A third field whose defining questions is closely related to ML is the study of human and animal learning in Psychology, Neuroscience, and related fields. Other field like biology, econonics to control theory also have a core interest in the question of how systems can automatically adapt or optimize to their environment. The mathematical models for adaptation inthese other fields are somewhat different from those commonly used in machine learning, suggesting significant potential for cross-fertilisation of models and theories.
\subsection{State of ML}
The real-world applications, such as those listed below.
\begin{enumerate}
\item \textit{Speech recognition}
\item \textit{Computer vision} like hand written addresses.
\item \textit{Bio-surveillance} like the RODS project.
\item \textit{Robot control} helicopter flight and helicopter aerobatics. The recent Darpa-sponsored competition involving a robot driving autonomously for over 100 miles in the desert was won by a robot that used machine learning to refine its ability to detect distant objects.
\item \textit{Accelerating empirical sciences}, many data-intensive sciences now make use of machine learning methods to aid in the scientific discovery process.
\end{enumerate}
\subsection{Place of Machine Learning within Computer Science}
In particular, machine learning methods are already the best methods available for developing particular types of software, in applications like:

\begin{enumerate}
\item The application in too complex for people to manually design the algorithm - sensor based perception task. computer vision.
\item The application requires that the software customise to its operational environment after it it fielded - speech recognition 
\end{enumerate}

By shifting the question from "how to program computers" to "how to allow them to program themselves", machine learning emphasise the design of self monitoring systems that self-diagnose and self-repair and on approaches that model their users, and the take advantage of the steady stream of data flowing through the program rather than simply processing it.

ML will help reshape the field of Statistics, by bringing a computational perspective to the fore, and raising issues such as never-ending learning.

Some current Research Questions:
\begin{enumerate}
\item \textit{Can unlabeled data be helpful for supervised learning?}
\item \textit{How can we transfer what is learned for one task to improve learning in other related tasks?}
\item \textit{What is the relationship between different learning algorithms, and which should be used when?}
\item \textit{For learners that actively collect their own training data, what is the best strategy?}
\item \textit{To what degree can we have both data privacy and the benefits of data mining?}
\end{enumerate}

The above research questions are already being energetically pursued by researchers in the field. It is also interesting to consider longer term research questions. Some additional research topics are some potential questions may significantly change the face of machine learning over the coming decades:
\begin{enumerate}
\item \textit{Can we build never-ending learners?} Learning in animals or human beings is an ongoing process in which the agent learns many different capabilities, often in a sequenced curriculum, and uses these different learned facts and capabilities in a highly synergistic fashion. - why not build machine learners that learn in this same cumulative way!
\item \textit{Can machine learning theories and algorithms help explain human learning?} Reinforce learning.
\item \textit{Can we design programming languages containing machine learning primitives?}
\item \textit{Will computer perception merge with machine learning?}
\end{enumerate}

\subsection{Where to Learn More}
Related Sources:
\begin{enumerate}
\item \textit{International Conference on Machine Learning.}
\item \textit{Conference on Neural Information Processing Systems.}
\item  \textit{Annual Conference on Learning Theory.}
\item  \textit{Journal of Machine Learning Research(JMLR) - www.jmlr.org}
\item  \textit{Machine Learning}
\end{enumerate}

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Decision Tree Learning (Based on Bishop Chapter 14.4)} 
By partitioning the input space into cuboid regions, whose edges are aligned with the axes, and then assigning a simple model to each region. The process of selecting a specific model, given a new input x, can be described by a sequential decision making process corresponding to the traversal of a binary tree. Here we focus on a particular tree-based framework called CART. Some other type of methods like ID3 and C4.5. 

....

In order to learn such a model from a training set, we have to determine {\color{red}{the structure of the tree}}, including which input variable is chosen at each node to form {\color{red}{the split criterion}} as well as {\color{red}{the valued of the threshold parameter $\theta_i$ for the split}}. We also have to determine the values of the predictive variable within each region.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------


\section{Lecture 1 of Mitchell}

\subsection{Concepts}
Machine learning:
	
Study of algorithms that 
\begin{enumerate}
\item[*] improve their performance P
\item[*] at some task T
\item[*] with experience E
\end{enumerate}
well-defined learning task:<P, T, E>.

\subsection{Learning to Predict Emergency C-Sections}
(Sims et al. 2000) A database with 9714 patient records each with 215 features.

Over training data: 26/41 = .63

Over test data: 12/20 = .60

- Data mining~ try to learn how to predict future~

\subsection{Learning to detect objects in images}
Example training images for each orientation.

\subsection{Learning to classify text documents.}
High dimensional data.
-Brain Image data.

\subsection{Machine learning - Practice}
Mining databases;

Speech Recognition; 

Control learning;

Object recognition;

Text analysis.

\subsection{Machine Learning - Theory}
PAC Learning Theory, supervised concept learning.
examples - $m$

representation complexity - $H$

error rate - $e$

failure probability - $\delta$


Other theories for Reinforcement skill learning,
semi-supervised learning
active student querying.

also relating:

\begin{itemize}
\item of mistakes during learning
\item learner's query strategy
\item convergence rate
\item asymptotic performance
\item bias, variance
\end{itemize}

\subsection{Machine Learning in Computer Science}

Machine Learning already the preferred approach to:
\begin{enumerate}
\item Speech recognition, Natural language processing
\item Computer vision
\item Medical outcomes analysis
\item Robot control
\end{enumerate}

This ML niche is growing, why ?

\subsection{Function Approximation and Decision Tree Learning}

have some function to some x to some y, 

Function approximation:

Problem Setting:
\begin{enumerate}
\item set of possible instance $X$
\item unknown target function $f:X -> Y$
\item set of function hypotheses $h=\{h|h:X->Y\}$
\end{enumerate}

Input:
- Traning examples$\{x^{(i)}\}$

Output:
Hypotheses $h\in H$ 


\subsection{Decision Tree Learning}

Problem Setting:

-Set of possible instances $S$

each instanc $x$ in $X$ is a feature vector

-Unknown target function $f:X->Y$

$Y$ is discrete valued

- Set of function hypotheses ~

\subsection{Decision Tree}
Suppose $X=<X_1, ... X_n>$ where $X_i$ are boolean variables.

Top-Down Induction of Decision Trees

[ID3, C4.5, Quinlan]

node = Root

Main loop:
\begin{enumerate}
\item $A<-$ the "best" decision attribute for next node
\item Assign $A$ as decision attribute for node
\item For each value of $A$, create new descendant of $node$
\item Sort training examples to leaf nodes
\item If training examples perfectly classified, then STOP, Else iterate over new leaf nodes.
\end{enumerate}

\subsection{Entropy}

Entropy $H(X)$ of a random variable $X$:


$H(X)$ is the expected number of bits needed to encode a randomly drawn value of $X$ (under most efficient code)

Why? Information theory:

Sample Entropy

Entropy measures the impurity of $S$.

Conditional entropy $H(X|Y = v)$

Information Gain is the mutual information between input attribute A and target variable Y. Information Gain is the expected reduction in entropy of target variable Y for data sample S, due to sorting on variable A.

\subsection{Applet}

\section{Review of Probability} 




Two-class classification probl em:
\begin{equation}
y(x) = w^T \phi(x) + b
\end{equation}
where $\phi$ denotes a fixed feature-space transformation, $ b$ explicit.

Training set comprises N input vectors $x_1, \cdots, x_N$ with target $t_1, /cdots, t_N$ where $t_N \in \{-1, 1\}$ and new data points are classified according to the sign of $y(x)$.

Training data - linearly separable in feature space, so  that there exits one choice of $w$ and $b$ such that by 1.1 satisfies $y(x_n)>0$ for points having $t_n=+1$ and $y(x_n)<0$ for $t_n=-1$.

In section 4, the perceptron algorithm is guaranteed to find a solution for the linearly separable problem. The solution deeps on the initial value and the order of the data points are presented - if there are multiple solutions we should try to find one with the smallest generalizaiton error.
SVM approaches this problem through the concept of the \textbf{margin} - the smallest distance between the decision boundary and any of the samples.

Perpendicular distance of a point $x$ from a hyperplane: $ {\lvert y(x) \rvert} / \lVert w \rVert$. We are only interested in solutions for which all data points are correctly classified ($t_n y(x_n)) >0$ for all n). So we have the distance of a point $x_n$ to the decision surface is given by:
\begin{equation}
\frac{t_ny(x_n)}{\lVert w \rVert} = \frac{t_n(w^T \phi(x_n)+b)}{\lVert w \rVert}
\end{equation}

{\color{red}{The margin is given by the perpendicular distance to the closest point $x_n$ from the data set, $w$ and $b$ need optimized in order to maximize the distance}}.

Then the maximum margin solution is found by
\begin{equation}
\argmax_{w, b} \{ \frac{1}{\lVert w \rVert} \min_n[t_n(w^T \phi(x_n)+b)]\}
\end{equation}

in which $\lVert w \rVert$ does not depend on $n$.
The direct solution of this optimization problem would be complex $\Rightarrow$ an equivalent problem easier to solve:

\begin{equation}
w \rightarrow \kappa w
\end{equation}

\begin{equation}
b \rightarrow \kappa b
\end{equation}
the rescaling would not change the distance.
We then use this freedom to set 
\begin{equation}
t_n(w^T \phi(x_n)+b)=1
\end{equation}
for the point that is closest to the surface.  

The canonical representation of the decision hyperplane:
\begin{equation}
t_n(w^T \phi(x_n)+b) \geq 1,   n = 1,\cdots, N
\end{equation}
When the equality holds, the constraints are said to be active.

There would always be at least one active constraint, because there will always be a closest point, and once the margin has been maximized there will be at leat two active constraints.  The optimization problem minimizing $\lVert w \rVert ^2$ is equivalent to maximize $\lVert w \rVert^{-1}$, so we need to solve the problem:
\begin{equation}
\argmin_{w,b} \frac{1}{2} \lVert w \rVert ^2
\end{equation}
subject to the constraints given by 1.7.

We introduce the Lagrange multipliers $a_n \geq 0$ with one multiplier $a_n$ for each of the constraints in1.7 giving the Lagrangian function:

\begin{equation}
L(w,b,a) = \frac{1}{2} \lVert w \rVert^2 - \sum_{n=1}^{N} a_n \{t_n(w^T \phi(x_n)+b)-1\}
\end{equation}
where $a=(a_1,\cdots,a_N)^T$.

Setting the derivatives of $L(w, b, a)$ with respect to $w$ abd $b$ equal to zero, we obtain the following conditions:
\begin{equation}
w= \sum_{n=1}^{N} a_n t_n \phi(x_n)
\end{equation}

\begin{equation}
0 = \sum_{n=1}^{N}a_nt_n
\end{equation}
Eliminating $w$ and $b$ from $L(w, b, a)$ using these conditions then gives the dual representation of the \textbf{maximum margin problem} in which we maximize
\begin{equation}
\tilde{L}(a) = \sum_{n=1}^{N}a_n - \frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N} a_na_mt_nt_mk(x_n,x_m)
\end{equation}
with respect to a subject to the constraints
\begin{equation}
a_n \geq 0,n = 1,\cdots,N
\end{equation}
\begin{equation}
\sum_{n=1}^{N}  a_nt_n = 0
\end{equation}

Here the kernel function is defined by $k(x, x')=\phi(x)^T\phi(x')$. This takes the form of a \textbf{quadratic programming problem}.

Computational complexity - $O(M^3)$.

{\color{red}{With dual formulation, the original optimization problem involved minimizing over $M$ variables into the dual problem with $N$ variables}}.

For fixed set of basis functions $M$ is smaller than the data points number $N$, dual representation seems useless.
However, it allows the model to be reformulated using kernels, and the maximum margin classifier can be applied efficiently to feature spaces whose dimensionality $M$ exceeds the number of data points $N$, including infinite feature spaces.

The kernel formulation also makes clear the role of the constraint that the kernel function $k(x, x')$ be \textbf{positive definite} - this ensures the Lagrangian function $\tilde{J}(a)$ is bounded below, giving rise to a well-defined optimization problem.

So new data point can be evaluated by:
\begin{equation}
y(x) = w^T\phi(x)+b = \sum_{n=1}^{N} a_n t_n k(x, x_n)+b
\end{equation}

For the Karush-Kuhn-Tucker KKT condtion, which in this case require that the following three properties hold:
\begin{equation}
a_n\geq0
\end{equation}
\begin{equation}
t_ny(x_n) - 1 \geq 0
\end{equation}
\begin{equation}
a_n\{t_n y(x_n)-1\} = 0
\end{equation}

------------------------------

check the Appendix E

------------------------------

For every data point, either $a_n=0$ or $t_ny(x_n)=1$, any data point for which $a_n=0$ will not appear in the sum in1.15 thus play no role in making predictions for new data points. \textbf{The remaining data points are called support vectors} - and they satisfy $t_ny(x_n)=1$, they lie on the maximum margin hyperplanes in feature space -- once the model is trained only the support vectors retained.

Solving the quadratic programming problem for $a$, determine $b$ by 
\begin{equation}
t_n(\sum_{m\in \mathcal{S}} a_mt_mk(x_n, x_m)+b)=1
\end{equation} where $\mathcal{S}$ denotes the set of indices of the support vectors.

A more stable solution for b is:
\begin{equation}
b=\frac{1}{N_{\mathcal{S}}} \sum_{m\in \mathcal{S}} (t_n - \sum_{m\in \mathcal{S}} a_mt_mk(x_n, x_m) )
\end{equation}
where $N_{\mathcal{S}}$ is the total number of support vectors.

\subsection{Overlapping class distributions}

\subsection{Relation to logistic regression}

\subsection{Multiclass SVMs}

\subsection{SVMs for regression}

\subsection{Computational learning theory}


%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------
\section{Relevance Vector Machines} 

\subsection{RVM for regression}

\subsection{Analysis of sparsity}

\subsection{RVM for classification}

%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------





%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------






%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------






%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------







%----------------------------------------------------------------------------------------
%	INTRO
%----------------------------------------------------------------------------------------

We now delve right into the proof.

\begin{lemma}
This is the first lemma of the lecture.
\end{lemma}

\begin{proof}
The proof is by induction on $\ldots$.
For fun, we throw in a figure.
%%%NOTE USAGE !
\fig{1}{1in}{A Fun Figure}

This is the end of the proof, which is marked with a little box.
\end{proof}

\subsection{A few items of note}

Here is an itemized list:
\begin{itemize}
\item this is the first item;
\item this is the second item.
\end{itemize}

Here is an enumerated list:
\begin{enumerate}
\item this is the first item;
\item this is the second item.
\end{enumerate}

Here is an exercise:

{\bf Exercise:}  Show that ${\rm P}\ne{\rm NP}$.

Here is how to define things in the proper mathematical style.
Let $f_k$ be the $AND-OR$ function, defined by

\[ f_k(x_1, x_2, \ldots, x_{2^k}) = \left\{ \begin{array}{ll}

	x_1 & \mbox{if $k = 0$;} \\

	AND(f_{k-1}(x_1, \ldots, x_{2^{k-1}}),
	   f_{k-1}(x_{2^{k-1} + 1}, \ldots, x_{2^k}))
	 & \mbox{if $k$ is even;} \\

	OR(f_{k-1}(x_1, \ldots, x_{2^{k-1}}),
	   f_{k-1}(x_{2^{k-1} + 1}, \ldots, x_{2^k}))	
	& \mbox{otherwise.} 
	\end{array}
	\right. \]

\begin{theorem}
This is the first theorem.
\end{theorem}

\begin{proof}
This is the proof of the first theorem. We show how to write pseudo-code now.
%*** USE PSEUDO-CODE ONLY IF IT IS CLEARER THAN AN ENGLISH DESCRIPTION

Consider a comparison between $x$ and~$y$:
\begin{tabbing}
\hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \=\kill
\>{\bf if} $x$ or $y$ or both are in $S$ {\bf then } \\
\>\> answer accordingly \\
\>{\bf else} \\
\>\>    Make the element with the larger score (say $x$) win the comparison \\
\>\> {\bf if} $F(x) + F(y) < \frac{n}{t-1}$ {\bf then} \\%
\>\>\> $F(x) \leftarrow F(x) + F(y)$ \\
\>\>\> $F(y) \leftarrow 0$ \\
\>\> {\bf else}  \\
\>\>\> $S \leftarrow S \cup \{ x \} $ \\
\>\>\> $r \leftarrow r+1$ \\
\>\> {\bf endif} \\
\>{\bf endif} 
\end{tabbing}

This concludes the proof.
\end{proof}


\section{Next topic}

Here is a citation, just for fun~\cite{CW87}.

\section*{References}
\beginrefs
\bibentry{CW87}{\sc D.~Coppersmith} and {\sc S.~Winograd}, 
``Matrix multiplication via arithmetic progressions,''
{\it Proceedings of the 19th ACM Symposium on Theory of Computing},
1987, pp.~1--6.
\endrefs

% **** THIS ENDS THE EXAMPLES. DON'T DELETE THE FOLLOWING LINE:

\end{document}





